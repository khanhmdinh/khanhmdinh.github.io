{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9444864-4eac-4702-ac15-c632f66dcb7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Extracting Checkpoint, Bronze, Silver containers URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7e7f6b2-f67e-433a-bc02-105039eb6c03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = spark.sql(\"describe external location `checkpoints`\").select(\"url\").collect()[0][0]\n",
    "bronze = spark.sql(\"describe external location `bronze`\").select(\"url\").collect()[0][0]\n",
    "silver = spark.sql(\"describe external location `silver`\").select(\"url\").collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3199bc7f-a40a-45d0-af21-edd89eda46b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(name=\"env\",defaultValue='',label='Enter the environment in lower case')\n",
    "env = dbutils.widgets.get(\"env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2ad8b83-e1d1-4390-8c99-f21323943b87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Reading the data from bronze Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3424c49f-3c66-4543-aefa-ad5ab534e9dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_BronzeTrafficTable(environment):\n",
    "    print('Reading the Bronze Table Data : ',end='')\n",
    "    df_bronzeTraffic = (spark.readStream\n",
    "                    .table(f\"`{environment}`.`bronze`.raw_traffic\")\n",
    "                    )\n",
    "    print(f'Reading {environment}.bronze.raw_traffic Success!')\n",
    "    return df_bronzeTraffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d4d8b52-6c9c-41e5-a35e-70a0e7b029c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Handing duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52023186-8b5e-4658-9fd5-c71d03145d62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def remove_Dups(df):\n",
    "    print('Removing Duplicate values: ', end='')\n",
    "    df_dup = df.dropDuplicates()\n",
    "    print('Success!! ')\n",
    "    return df_dup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc4b49b1-2422-43d5-bc83-94622ac62999",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Handling NULL values by replacing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eecff639-74a4-497e-9428-200b2a01ef56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def handle_NULLs(df,columns):\n",
    "    print('Replacing NULL values on String Columns with \"Unknown\" ' , end='')\n",
    "    df_string = df.fillna('Unknown',subset= columns)\n",
    "    print('Successs!! ')\n",
    "\n",
    "    print('Replacing NULL values on Numeric Columns with \"0\" ' , end='')\n",
    "    df_clean = df_string.fillna(0,subset = columns)\n",
    "    print('Success!! ')\n",
    "\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "415a49e6-3292-4992-9cde-584a95e8002a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Getting count of Electric vehicles by creating new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e726c33-398f-4534-b90d-f549dbd60121",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def ev_Count(df):\n",
    "    print('Creating Electric Vehicles Count Column : ', end='')\n",
    "    from pyspark.sql.functions import col\n",
    "    df_ev = df.withColumn('Electric_Vehicles_Count',\n",
    "                            col('EV_Car') + col('EV_Bike')\n",
    "                            )\n",
    "    \n",
    "    print('Success!! ')\n",
    "    return df_ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f090aab4-fb74-418c-bf0b-1f0ebb8531b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Creating columns to get Count of all motor vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eff0822f-1fb5-48b1-bd81-a574616d689e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def Motor_Count(df):\n",
    "    print('Creating All Motor Vehicles Count Column : ', end='')\n",
    "    from pyspark.sql.functions import col\n",
    "    df_motor = df.withColumn('Motor_Vehicles_Count',\n",
    "                            col('Electric_Vehicles_Count') + col('Two_wheeled_motor_vehicles') + col('Cars_and_taxis') + col('Buses_and_coaches') + col('LGV_Type') + col('HGV_Type')\n",
    "                            )\n",
    "    \n",
    "    print('Success!! ')\n",
    "    return df_motor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5784cad-2631-4fb5-8420-df6973942b90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Creating Transformed Time column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2a6ed2a-7353-403f-b131-cbed81658af4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_TransformedTime(df):\n",
    "    from pyspark.sql.functions import current_timestamp\n",
    "    print('Creating Transformed Time column : ',end='')\n",
    "    df_timestamp = df.withColumn('Transformed_Time',\n",
    "                      current_timestamp()\n",
    "                      )\n",
    "    print('Success!!')\n",
    "    return df_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2476bd5c-e803-42a1-964d-e1c91c10fd36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Writing the Transformed data to Silver_Traffic Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2143e7d-b337-4027-9621-a63efd7d5d36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def write_Traffic_SilverTable(StreamingDF,environment):\n",
    "    print('Writing the silver_traffic Data : ',end='') \n",
    "\n",
    "    write_StreamSilver = (StreamingDF.writeStream\n",
    "                .format('delta')\n",
    "                .option('checkpointLocation',checkpoint+ \"/SilverTrafficLoad/Checkpt/\")\n",
    "                .outputMode('append')\n",
    "                .queryName(\"SilverTrafficWriteStream\")\n",
    "                .trigger(availableNow=True)\n",
    "                .toTable(f\"`{environment}`.`silver`.`silver_traffic`\"))\n",
    "    \n",
    "    write_StreamSilver.awaitTermination()\n",
    "    print(f'Writing `{environment}_catalog`.`silver`.`silver_traffic` Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ebe08ec-c66a-46f8-b7ef-4ace02592a74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Calling the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f070a7ba-b8b7-4e85-81b2-3dc62b53dabd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the Bronze Table Data : Reading databricks_dev_wp.bronze.raw_traffic Success!\nRemoving Duplicate values: Success!! \nReplacing NULL values on String Columns with \"Unknown\" Successs!! \nReplacing NULL values on Numeric Columns with \"0\" Success!! \nCreating Electric Vehicles Count Column : Success!! \nCreating All Motor Vehicles Count Column : Success!! \nCreating Transformed Time column : Success!!\nWriting the silver_traffic Data : Writing `databricks_dev_wp_catalog`.`silver`.`silver_traffic` Success!\n"
     ]
    }
   ],
   "source": [
    "## Reading the bronze traffic data\n",
    "\n",
    "df_trafficdata = read_BronzeTrafficTable(env)\n",
    "\n",
    "# To remove duplicate rows\n",
    "\n",
    "df_dups = remove_Dups(df_bronzeTraffic)\n",
    "\n",
    "# To replace any NULL values\n",
    "Allcolums = df_dups.schema.names\n",
    "df_nulls = handle_NULLs(df_dups,Allcolums)\n",
    "\n",
    "# To get the total EV_Count\n",
    "df_ev = ev_Count(df_nulls)\n",
    "\n",
    "# To get the total motor vehicle count\n",
    "df_motor = Motor_Count(df_ev)\n",
    "\n",
    "# Calling Transformed Time function\n",
    "\n",
    "df_final = create_TransformedTime(df_motor)\n",
    "\n",
    "## Writing to silver_traffic\n",
    "\n",
    "write_Traffic_SilverTable(df_final, env)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": {
    "autoRunOnWidgetChange": "auto-run-all"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03. Silver - Traffic Transformations",
   "widgets": {
    "env": {
     "currentValue": "databricks_dev_wp",
     "nuid": "f6fcdb1d-95ad-431e-990a-044bcde5c123",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Enter the environment in lower case",
      "name": "env",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Enter the environment in lower case",
      "name": "env",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}